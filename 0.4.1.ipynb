{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyMIh8y9hZiyKnCn6ymZ3ycB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamBrudell/report.clean/blob/main/0.4.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZIS6Hh2qBLu",
        "outputId": "d574f38c-633f-4caa-a44d-7dc224dba571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pR8Jp7zOGV5OmWVa_5VuFBQlppK15Hi4\n",
            "To: /content/downloaded_file.csv\n",
            "100%|██████████| 19.2M/19.2M [00:00<00:00, 192MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded to: downloaded_file.csv\n",
            "File read successfully!\n",
            "'Cost Centre' column exists! Proceeding with splitting...\n",
            "Excel file '/content/drive/My Drive/split_data_with_analysis.xlsx' created successfully with analysis sheets!\n",
            "Filtered CSV file saved to Google Drive at: /content/drive/My Drive/filtered_file.csv\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)  # Ensures a fresh connection\n",
        "\n",
        "# Google Drive file ID (Replace with your actual file ID)\n",
        "file_id = '1pR8Jp7zOGV5OmWVa_5VuFBQlppK15Hi4'  # Replace with your actual file ID\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Download file from Google Drive\n",
        "output_file_path = 'downloaded_file.csv'\n",
        "gdown.download(url, output_file_path, quiet=False)\n",
        "print(f\"File downloaded to: {output_file_path}\")\n",
        "\n",
        "# Read the CSV file with encoding handling\n",
        "try:\n",
        "    df = pd.read_csv(output_file_path, encoding='ISO-8859-1')  # Try ISO-8859-1 encoding first\n",
        "    print(\"File read successfully!\")\n",
        "except UnicodeDecodeError:\n",
        "    print(f\"Error reading the file with 'ISO-8859-1' encoding, trying 'utf-16' encoding...\")\n",
        "    df = pd.read_csv(output_file_path, encoding='utf-16')\n",
        "\n",
        "# Check if 'Cost Centre' column exists\n",
        "if 'Cost Centre' not in df.columns:\n",
        "    print(f\"Error: Column 'Cost Centre' not found in the dataset!\")\n",
        "    print(\"Available columns:\", df.columns.tolist())  # Debugging step\n",
        "else:\n",
        "    print(f\"'Cost Centre' column exists! Proceeding with splitting...\")\n",
        "\n",
        "# List of columns to delete (if they exist)\n",
        "columns_to_delete = [\n",
        "    'Entity', 'GL Date', 'Intercompany', 'Source', 'Category', 'Event Class',\n",
        "    'Journal Batch', 'Journal', 'Currency', 'Currency Amount', 'Total Value'\n",
        "]\n",
        "df = df.drop(columns=[col for col in columns_to_delete if col in df.columns], errors='ignore')\n",
        "\n",
        "# Function to extract the numeric value from a string (text format)\n",
        "def extract_numeric_value(text):\n",
        "    match = re.search(r'(\\d+\\.?\\d*)', str(text))\n",
        "    return float(match.group(1)) if match else None\n",
        "\n",
        "# If 'Account' column exists, extract numeric values and keep specific numbers\n",
        "if 'Account' in df.columns:\n",
        "    df['Account_numeric'] = df['Account'].apply(extract_numeric_value)\n",
        "\n",
        "    # List of specific numbers to keep\n",
        "    keep_numbers = [\n",
        "        1518, 2410, 2646, 2689, 2681, 2682, 2341, 3092, 2388, 2322, 2644, 2412,\n",
        "        2391, 2841, 2688, 2852, 2385, 2321, 2384, 2352, 2683, 2735, 2405, 2377,\n",
        "        2374, 2362, 2823, 2685, 2643, 2373, 2733, 2351, 2371, 3064, 2342, 2379,\n",
        "        2731, 2851, 2762, 2642, 2411, 2425, 2361, 2858, 2418, 2842, 2421, 2684,\n",
        "        2737, 2736, 2381, 2413, 2734, 2952, 2822, 2378, 2380, 2430, 2395, 1519,\n",
        "        2404\n",
        "    ]\n",
        "\n",
        "    # Keep only rows where 'Account_numeric' is in keep_numbers\n",
        "    df = df[df['Account_numeric'].isin(keep_numbers)]\n",
        "\n",
        "    # Drop temporary column\n",
        "    df.drop(columns=['Account_numeric'], inplace=True)\n",
        "\n",
        "# Column to split data by\n",
        "column_name = \"Cost Centre\"  # Ensure this matches exactly\n",
        "\n",
        "# Function to sanitize sheet names (Excel limit: 31 characters)\n",
        "def sanitize_sheet_name(name, max_length=31):\n",
        "    sanitized = re.sub(r'[\\/:*?\"<>|]', '_', str(name))  # Replace invalid characters\n",
        "    # Ensure the sheet name plus \"_Stats\" is no more than 31 characters\n",
        "    stats_suffix = \"_Stats\"\n",
        "    if len(sanitized) + len(stats_suffix) > max_length:\n",
        "        sanitized = sanitized[:max_length - len(stats_suffix)]  # Keep space for \"_Stats\"\n",
        "    return sanitized\n",
        "\n",
        "# Output path for the final Excel file\n",
        "output_excel_path = \"/content/drive/My Drive/split_data_with_analysis.xlsx\"\n",
        "\n",
        "# Ensure column exists before proceeding\n",
        "if column_name not in df.columns:\n",
        "    print(f\"Error: Column '{column_name}' not found in the dataset!\")\n",
        "else:\n",
        "    with pd.ExcelWriter(output_excel_path, engine=\"xlsxwriter\") as writer:\n",
        "        for value, subset in df.groupby(column_name):\n",
        "            sheet_name = sanitize_sheet_name(value)  # Ensure valid sheet name\n",
        "\n",
        "            # Select only numeric columns for analysis\n",
        "            numeric_cols = subset.select_dtypes(include=['number'])\n",
        "\n",
        "            # Compute advanced statistics\n",
        "            if not numeric_cols.empty:\n",
        "                stats = numeric_cols.describe().T[['count', 'mean', 'min', 'max']]\n",
        "                stats['sum'] = numeric_cols.sum()\n",
        "                stats['std_dev'] = numeric_cols.std()\n",
        "                stats['median'] = numeric_cols.median()\n",
        "                stats['variance'] = numeric_cols.var()\n",
        "                stats['iqr'] = numeric_cols.quantile(0.75) - numeric_cols.quantile(0.25)  # Interquartile Range\n",
        "                stats.reset_index(inplace=True)  # Reset index to make it easy to read\n",
        "\n",
        "                # Write subset data\n",
        "                subset.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "                # Write statistics sheet for each group\n",
        "                stats.to_excel(writer, sheet_name=f\"{sheet_name}_Stats\", index=False)\n",
        "            else:\n",
        "                print(f\"Warning: No numeric data to analyze for '{sheet_name}'.\")\n",
        "\n",
        "    print(f\"Excel file '{output_excel_path}' created successfully with analysis sheets!\")\n",
        "\n",
        "# Save final filtered CSV file to Google Drive\n",
        "output_csv_path_filtered = \"/content/drive/My Drive/filtered_file.csv\"\n",
        "df.to_csv(output_csv_path_filtered, index=False)\n",
        "print(f\"Filtered CSV file saved to Google Drive at: {output_csv_path_filtered}\")\n",
        "\n"
      ]
    }
  ]
}
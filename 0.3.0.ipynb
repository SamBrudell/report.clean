{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBsRnQCbviVjzrNd2ZKcuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamBrudell/report.clean/blob/V1/0.3.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCbbLAVS-9PU"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')  # Will prompt for authentication\n",
        "\n",
        "# Google Drive file ID (Replace with your actual file ID)\n",
        "file_id = '1pR8Jp7zOGV5OmWVa_5VuFBQlppK15Hi4'  # Replace with your actual file ID\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Download file from Google Drive\n",
        "output_file_path = 'downloaded_file.csv'\n",
        "gdown.download(url, output_file_path, quiet=False)\n",
        "print(f\"File downloaded to: {output_file_path}\")\n",
        "\n",
        "# Read the CSV file with encoding handling\n",
        "try:\n",
        "    df = pd.read_csv(output_file_path, encoding='ISO-8859-1')  # Try ISO-8859-1 encoding first\n",
        "    print(\"File read successfully!\")\n",
        "except UnicodeDecodeError:\n",
        "    print(f\"Error reading the file with 'ISO-8859-1' encoding, trying 'utf-16' encoding...\")\n",
        "    df = pd.read_csv(output_file_path, encoding='utf-16')\n",
        "\n",
        "# Check if the 'Cost Centre' column exists\n",
        "if 'Cost Centre' not in df.columns:\n",
        "    print(f\"Error: Column 'Cost Centre' not found in the dataset!\")\n",
        "    print(\"Available columns:\", df.columns.tolist())  # Debugging step\n",
        "else:\n",
        "    print(f\"'Cost Centre' column exists! Proceeding with splitting...\")\n",
        "\n",
        "# List of columns to delete (if they exist)\n",
        "columns_to_delete = [\n",
        "    'Entity', 'GL Date', 'Intercompany', 'Source', 'Category', 'Event Class',\n",
        "    'Journal Batch', 'Journal', 'Currency', 'Currency Amount', 'Total Value'\n",
        "]\n",
        "df = df.drop(columns=[col for col in columns_to_delete if col in df.columns], errors='ignore')\n",
        "\n",
        "# Function to extract the numeric value from a string (text format)\n",
        "def extract_numeric_value(text):\n",
        "    match = re.search(r'(\\d+\\.?\\d*)', str(text))\n",
        "    return float(match.group(1)) if match else None\n",
        "\n",
        "# If 'Account' column exists, extract numeric values and keep specific numbers\n",
        "if 'Account' in df.columns:\n",
        "    df['Account_numeric'] = df['Account'].apply(extract_numeric_value)\n",
        "\n",
        "    # List of specific numbers to keep\n",
        "    keep_numbers = [\n",
        "        1518, 2410, 2646, 2689, 2681, 2682, 2341, 3092, 2388, 2322, 2644, 2412,\n",
        "        2391, 2841, 2688, 2852, 2385, 2321, 2384, 2352, 2683, 2735, 2405, 2377,\n",
        "        2374, 2362, 2823, 2685, 2643, 2373, 2733, 2351, 2371, 3064, 2342, 2379,\n",
        "        2731, 2851, 2762, 2642, 2411, 2425, 2361, 2858, 2418, 2842, 2421, 2684,\n",
        "        2737, 2736, 2381, 2413, 2734, 2952, 2822, 2378, 2380, 2430, 2395, 1519,\n",
        "        2404\n",
        "    ]\n",
        "\n",
        "    # Keep only rows where 'Account_numeric' is in keep_numbers\n",
        "    df = df[df['Account_numeric'].isin(keep_numbers)]\n",
        "\n",
        "    # Drop temporary column\n",
        "    df.drop(columns=['Account_numeric'], inplace=True)\n",
        "\n",
        "# Column to split data by (Update if necessary)\n",
        "column_name = \"Cost Centre\"  # Make sure this matches exactly\n",
        "\n",
        "# Ensure column exists before proceeding\n",
        "if column_name not in df.columns:\n",
        "    print(f\"Error: Column '{column_name}' not found in the dataset!\")\n",
        "else:\n",
        "    # Function to sanitize sheet names (remove invalid characters)\n",
        "    def sanitize_sheet_name(name):\n",
        "        # Replace any invalid characters with an underscore (_)\n",
        "        return re.sub(r'[\\\\/:*?\"<>|]', '_', str(name))[:31]  # Max length for sheet name is 31 characters\n",
        "\n",
        "    # Save filtered data into separate Excel sheets\n",
        "    output_excel_path = \"/content/drive/My Drive/split_data.xlsx\"  # Save to Google Drive\n",
        "\n",
        "    with pd.ExcelWriter(output_excel_path, engine=\"xlsxwriter\") as writer:\n",
        "        for value, subset in df.groupby(column_name):\n",
        "            # Sanitize sheet name before writing\n",
        "            sanitized_value = sanitize_sheet_name(value)\n",
        "            subset.to_excel(writer, sheet_name=sanitized_value, index=False)  # Ensure sheet name is valid\n",
        "\n",
        "    print(f\"Excel file '{output_excel_path}' created successfully!\")\n",
        "\n",
        "# Save final filtered CSV file to Google Drive (Do not use ExcelWriter for CSV)\n",
        "output_csv_path_filtered = \"/content/drive/My Drive/filtered_file.csv\"\n",
        "df.to_csv(output_csv_path_filtered, index=False)\n",
        "print(f\"Filtered CSV file saved to Google Drive at: {output_csv_path_filtered}\")"
      ]
    }
  ]
}